{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -43.45092138266382\n",
      "p-value: 0.0\n",
      "Critical Values: {'1%': np.float64(-3.4355754676859886), '5%': np.float64(-2.8638475772391665), '10%': np.float64(-2.5679985805677017)}\n",
      "Is the series stationary? True\n",
      "Training data shape: (1235, 6)\n",
      "Testing data shape: (20, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"S&P500_L5Y.csv\"  # Update this if needed\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert Date column to datetime format and sort in ascending order\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%Y')\n",
    "df = df.sort_values(by='Date')\n",
    "\n",
    "# Rename 'Close/Last' for easier reference\n",
    "df.rename(columns={'Close/Last': 'Close'}, inplace=True)\n",
    "\n",
    "# Compute log returns\n",
    "df['Log_Returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "\n",
    "# Drop first row due to NaN in log returns\n",
    "df = df.dropna()\n",
    "\n",
    "# Perform Augmented Dickey-Fuller test\n",
    "adf_test = adfuller(df['Log_Returns'])\n",
    "print(\"ADF Statistic:\", adf_test[0])\n",
    "print(\"p-value:\", adf_test[1])\n",
    "print(\"Critical Values:\", adf_test[4])\n",
    "print(\"Is the series stationary?\", adf_test[1] < 0.05)  # Null hypothesis: non-stationary\n",
    "\n",
    "# Split into training (256 weeks) and testing (4 weeks)\n",
    "train_size = 256 * 5  # 1280 days\n",
    "test_size = 4 * 5  # 20 days\n",
    "\n",
    "train_data = df.iloc[:-test_size]  # All but the last 20 days\n",
    "test_data = df.iloc[-test_size:]  # Last 20 days\n",
    "\n",
    "# Save to CSV if needed\n",
    "train_data.to_csv(\"train_data.csv\", index=False)\n",
    "test_data.to_csv(\"test_data.csv\", index=False)\n",
    "\n",
    "print(\"Training data shape:\", train_data.shape)\n",
    "print(\"Testing data shape:\", test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load preprocessed data\n",
    "df = pd.read_csv(\"train_data.csv\")  # Load the training dataset\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Plot ACF and PACF to determine p and q\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "plot_acf(df['Log_Returns'], ax=axes[0])  # Identify q\n",
    "plot_pacf(df['Log_Returns'], ax=axes[1])  # Identify p\n",
    "plt.show()\n",
    "\n",
    "# Fit ARIMA model (use d=0 since log returns are already stationary)\n",
    "p, d, q = 1, 0, 1  # Adjust based on ACF/PACF analysis\n",
    "model = ARIMA(df['Log_Returns'], order=(p, d, q))\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model_fit.summary())\n",
    "\n",
    "# Forecast future log returns for the test period\n",
    "test_df = pd.read_csv(\"test_data.csv\")\n",
    "test_df['Date'] = pd.to_datetime(test_df['Date'])\n",
    "test_df.set_index('Date', inplace=True)\n",
    "\n",
    "forecast = model_fit.forecast(steps=len(test_df))\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = np.sqrt(mean_squared_error(test_df['Log_Returns'], forecast))\n",
    "mae = mean_absolute_error(test_df['Log_Returns'], forecast)\n",
    "\n",
    "print(f\"RMSE: {rmse:.5f}\")\n",
    "print(f\"MAE: {mae:.5f}\")\n",
    "\n",
    "# Plot actual vs. predicted\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(test_df.index, test_df['Log_Returns'], label=\"Actual Log Returns\", marker='o')\n",
    "plt.plot(test_df.index, forecast, label=\"Predicted Log Returns\", linestyle='dashed', marker='x')\n",
    "plt.legend()\n",
    "plt.title(\"ARIMA Forecast vs Actual\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8da2dd7a38495f92fef7f207b3f0cca2972eb2be1af0e86eef515a1c9c6fb7fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
